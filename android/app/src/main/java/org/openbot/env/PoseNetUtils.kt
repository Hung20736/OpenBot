package org.openbot.env

import android.content.ContentValues.TAG
import android.graphics.*
import android.hardware.camera2.CameraCaptureSession
import android.hardware.camera2.CameraDevice
import android.hardware.camera2.CaptureRequest
import android.media.ImageReader
import android.os.Handler
import android.os.HandlerThread
import android.util.Log
import android.util.Pair
import android.util.Size
import android.view.SurfaceHolder
import android.view.SurfaceView
import org.openbot.CameraActivity
import org.tensorflow.lite.examples.posenet.lib.BodyPart
import org.tensorflow.lite.examples.posenet.lib.Person
import org.tensorflow.lite.examples.posenet.lib.Posenet
import java.lang.Math.abs
import java.util.concurrent.Semaphore

/** Model input shape for images.   */
const val MODEL_WIDTH = 257
const val MODEL_HEIGHT = 257

class PoseNetUtils {
    val bodyJoints = listOf(
            Pair(BodyPart.LEFT_WRIST, BodyPart.LEFT_ELBOW),
            Pair(BodyPart.LEFT_ELBOW, BodyPart.LEFT_SHOULDER),
            Pair(BodyPart.LEFT_SHOULDER, BodyPart.RIGHT_SHOULDER),
            Pair(BodyPart.RIGHT_SHOULDER, BodyPart.RIGHT_ELBOW),
            Pair(BodyPart.RIGHT_ELBOW, BodyPart.RIGHT_WRIST),
            Pair(BodyPart.LEFT_SHOULDER, BodyPart.LEFT_HIP),
            Pair(BodyPart.LEFT_HIP, BodyPart.RIGHT_HIP),
            Pair(BodyPart.RIGHT_HIP, BodyPart.RIGHT_SHOULDER),
            Pair(BodyPart.LEFT_HIP, BodyPart.LEFT_KNEE),
            Pair(BodyPart.LEFT_KNEE, BodyPart.LEFT_ANKLE),
            Pair(BodyPart.RIGHT_HIP, BodyPart.RIGHT_KNEE),
            Pair(BodyPart.RIGHT_KNEE, BodyPart.RIGHT_ANKLE)
    )
    companion object{
        // instance
        val instance by lazy { PoseNetUtils() }
    }



    /** Threshold for confidence score. */
    val minConfidence = 0.5

    /** Radius of circle used to draw keypoints.  */
    val circleRadius = 8.0f

    /** Paint class holds the style and color information to draw geometries,text and bitmaps. */
    var paint = Paint()

    /** A shape for extracting frame data.   */
    val PREVIEW_WIDTH = 640
    val PREVIEW_HEIGHT = 480

    /** An object for the Posenet library.    */
    lateinit var posenet: Posenet

    /** ID of the current [CameraDevice].   */
    var cameraId: String? = null

    /** A [SurfaceView] for camera preview.   */
    var surfaceView: SurfaceView? = null

    /** A [CameraCaptureSession] for camera preview.   */
    var captureSession: CameraCaptureSession? = null

    /** A reference to the opened [CameraDevice].    */
    var cameraDevice: CameraDevice? = null

    /** The [android.util.Size] of camera preview.  */
    var previewSize: Size? = null

    /** The [android.util.Size.getWidth] of camera preview. */
    var previewWidth = 0

    /** The [android.util.Size.getHeight] of camera preview.  */
    var previewHeight = 0

    /** A counter to keep count of total frames.  */
    var frameCounter = 0

    /** An IntArray to save image data in ARGB8888 format  */
    lateinit var rgbBytes: IntArray

    /** A ByteArray to save image data in YUV format  */
    var yuvBytes = arrayOfNulls<ByteArray>(3)

    /** An additional thread for running tasks that shouldn't block the UI.   */
    var backgroundThread: HandlerThread? = null

    /** A [Handler] for running tasks in the background.    */
    var backgroundHandler: Handler? = null

    /** An [ImageReader] that handles preview frame capture.   */
    var imageReader: ImageReader? = null

    /** [CaptureRequest.Builder] for the camera preview   */
    var previewRequestBuilder: CaptureRequest.Builder? = null

    /** [CaptureRequest] generated by [.previewRequestBuilder   */
    var previewRequest: CaptureRequest? = null

    /** A [Semaphore] to prevent the app from exiting before closing the camera.    */
    val cameraOpenCloseLock = Semaphore(1)

    /** Whether the current camera device supports Flash or not.    */
    var flashSupported = false

    /** Orientation of the camera sensor.   */
    var sensorOrientation: Int? = null

    /** Abstract interface to someone holding a display surface.    */
    private var surfaceholder: SurfaceHolder? = null

    /** Abstract interface to someone holding a display surface.    */

    public fun cropBitmap(bitmap: Bitmap): Bitmap {
        val bitmapRatio = bitmap.height.toFloat() / bitmap.width
        val modelInputRatio = MODEL_HEIGHT.toFloat() / MODEL_WIDTH
        var croppedBitmap = bitmap

        // Acceptable difference between the modelInputRatio and bitmapRatio to skip cropping.
        val maxDifference = 1e-5

        // Checks if the bitmap has similar aspect ratio as the required model input.
        when {
            abs(modelInputRatio - bitmapRatio) < maxDifference -> return croppedBitmap
            modelInputRatio < bitmapRatio -> {
                // New image is taller so we are height constrained.
                val cropHeight = bitmap.height - (bitmap.width.toFloat() / modelInputRatio)
                croppedBitmap = Bitmap.createBitmap(
                        bitmap,
                        0,
                        (cropHeight / 2).toInt(),
                        bitmap.width,
                        (bitmap.height - cropHeight).toInt()
                )
            }
            else -> {
                val cropWidth = bitmap.width - (bitmap.height.toFloat() * modelInputRatio)
                croppedBitmap = Bitmap.createBitmap(
                        bitmap,
                        (cropWidth / 2).toInt(),
                        0,
                        (bitmap.width - cropWidth).toInt(),
                        bitmap.height
                )
            }
        }
        return croppedBitmap
    }

    public fun processImage(bitmap: Bitmap,  surfaceHolder: SurfaceHolder) {
        // Crop bitmap.
        posenet = Posenet(CameraActivity.getContext())
        val croppedBitmap = cropBitmap(bitmap)

        // Created scaled version of bitmap for model input.
        val scaledBitmap = Bitmap.createScaledBitmap(croppedBitmap, MODEL_WIDTH, MODEL_HEIGHT, true)

        // Perform inference.
        val person = posenet.estimateSinglePose(scaledBitmap)
        surfaceholder = surfaceHolder
        if (surfaceholder == null) {
            Log.d("#Surface Holder", "Surface holder is null")
            return;
        } else {
            Log.d("#Surface Holder", "Surface holder is not null")
            val canvas: Canvas = surfaceholder!!.lockCanvas()
            draw(canvas, person, scaledBitmap)
            posenet.close()
        }

    }

    public fun draw(canvas: Canvas, person: Person, bitmap: Bitmap) {
        canvas.drawColor(Color.TRANSPARENT, PorterDuff.Mode.CLEAR)
        // Draw `bitmap` and `person` in square canvas.
        val screenWidth: Int
        val screenHeight: Int
        val left: Int
        val right: Int
        val top: Int
        val bottom: Int
        if (canvas.height > canvas.width) {
            screenWidth = canvas.width
            screenHeight = canvas.width
            left = 0
            top = (canvas.height - canvas.width) / 2
        } else {
            screenWidth = canvas.height
            screenHeight = canvas.height
            left = (canvas.width - canvas.height) / 2
            top = 0
        }
        right = left + screenWidth
        bottom = top + screenHeight

        setPaint()
        canvas.drawBitmap(
                bitmap,
                Rect(0, 0, bitmap.width, bitmap.height),
                Rect(left, top, right, bottom),
                paint
        )

        val widthRatio = screenWidth.toFloat() / MODEL_WIDTH
        val heightRatio = screenHeight.toFloat() / MODEL_HEIGHT

        // Draw key points over the image.
        for (keyPoint in person.keyPoints) {
            if (keyPoint.score > minConfidence) {
                val position = keyPoint.position
                val adjustedX: Float = position.x.toFloat() * widthRatio + left
                val adjustedY: Float = position.y.toFloat() * heightRatio + top
                canvas.drawCircle(adjustedX, adjustedY, circleRadius, paint)
            }
        }

        for (line in bodyJoints) {
            if (
                    (person.keyPoints[line.first.ordinal].score > minConfidence) and
                    (person.keyPoints[line.second.ordinal].score > minConfidence)
            ) {
                canvas.drawLine(
                        person.keyPoints[line.first.ordinal].position.x.toFloat() * widthRatio + left,
                        person.keyPoints[line.first.ordinal].position.y.toFloat() * heightRatio + top,
                        person.keyPoints[line.second.ordinal].position.x.toFloat() * widthRatio + left,
                        person.keyPoints[line.second.ordinal].position.y.toFloat() * heightRatio + top,
                        paint
                )
            }
        }

        canvas.drawText(
                "Score: %.2f".format(person.score),
                (15.0f * widthRatio),
                (30.0f * heightRatio + bottom),
                paint
        )
        canvas.drawText(
                "Device: %s".format(posenet.device),
                (15.0f * widthRatio),
                (50.0f * heightRatio + bottom),
                paint
        )
        canvas.drawText(
                "Time: %.2f ms".format(posenet.lastInferenceTimeNanos * 1.0f / 1_000_000),
                (15.0f * widthRatio),
                (70.0f * heightRatio + bottom),
                paint
        )

        // Draw!
        surfaceholder!!.unlockCanvasAndPost(canvas)
    }

    protected fun setPaint() {
        paint.color = Color.RED
        paint.textSize = 80.0f
        paint.strokeWidth = 8.0f
    }


    protected fun stopBackgroundThread() {
        backgroundThread?.quitSafely()
        try {
            backgroundThread?.join()
            backgroundThread = null
            backgroundHandler = null
        } catch (e: InterruptedException) {
            Log.e(TAG, e.toString())
        }
    }
}
